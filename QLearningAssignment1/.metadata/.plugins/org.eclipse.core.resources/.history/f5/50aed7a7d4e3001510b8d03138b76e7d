import java.text.DecimalFormat;
import java.util.ArrayList;
import java.util.Random;
import java.nio.file.Paths;
import java.io.*;
import java.io.FileWriter;
import java.io.IOException;
import java.io.BufferedWriter;
 
/**
 * Will and Olivia
 */

public class Qlearning {
    final DecimalFormat df = new DecimalFormat("0.0");
 
    private Random random = new Random();
    
    // path finding
    final double alpha = 0.1;
    final double gamma = 0.9;
    final int epsilon = 20;
    static double showalpha = 0.1;
    static double showgamma = 0.9;
    static int showepsilon = 10;
 
 
// states A,B,C,D,E,F
// e.g. from A we can go to B or D
// from C we can only go to C 
// C is goal state, reward 100 when B->C or F->C
// 
// _________
// |A|B|C|D|
// |_______|
// |E|F|G|H|
// |_______|
// |I|J|K|L|
// |_______|
// |M|N|O|P|
// |_______|
//
 
    /*
    final int stateA = 0;
    final int stateB = 1;
    final int stateC = 2;
    final int stateD = 3;
    final int stateE = 4;
    final int stateF = 5;
    final int stateG = 6;
    final int stateH = 7;
    final int stateI = 8;
    final int stateJ = 9;
    final int stateK = 10;
    final int stateL = 11;
    final int stateM = 12;
    final int stateN = 13;
    final int stateO = 14;
    final int stateP = 15;
    */
 
    
    //Stored random number seeds
    final long seedZero = 3;
    
    final int xWidth = 4;
    final int yWidth = 4;
    final int statesCount = 100;
    
    final int c_maxAdjacentSides = 4;
    
    int m_goalStateX;
    int m_goalStateY;
    
    static class Pair{
    	public Pair(){
    	}
    	
    	public Pair(Pair c){
    		x = c.x;
    		y = c.y;
    	}
    	
    	public boolean IsSame(Pair c){
    		return c.x == x && c.y == y;
    	}
    	
    	public int x;
    	public int y;
    }
    
    final int[][] states = new int[xWidth][yWidth];
    Pair[][][] actions;
    
    
    // http://en.wikipedia.org/wiki/Q-learning
    // http://people.revoledu.com/kardi/tutorial/ReinforcementLearning/Q-Learning.htm
 
    // Q(s,a)= Q(s,a) + alpha * (R(s,a) + gamma * Max(next state, all actions) - Q(s,a))
 
    boolean[][] m_disconnectedCells = new boolean[xWidth][yWidth];
    
    int[][][][] R = new int[xWidth][yWidth][xWidth][yWidth]; // reward lookup
    double[][][][] Q = new double[xWidth][yWidth][xWidth][yWidth]; // Q learning
 
    String[][] stateNames;
 
    public Qlearning() {
        init();
    }
 
    
    public boolean GapExceeds(Pair newPair, int highestX, int lowestX, int highestY, int lowestY, ArrayList<Pair> visited){
    	boolean contained = false;
    	
    	for(int i = 0; i < visited.size(); i++){
    		if(visited.get(i).IsSame(newPair)){
    			contained = true;
    			i = visited.size();
    		}
    	}
    	
    	
    	if(contained){
    		return (highestX - lowestX <= 1 && highestY-lowestY <= 1);
    	}
    	visited.add(newPair);
    	if(newPair.x < 0 || newPair.y < 0 || newPair.x >= xWidth || newPair.y >= yWidth || !(highestX - lowestX <= 1 && highestY-lowestY <= 1)){
    		return (highestX - lowestX <= 1 && highestY-lowestY <= 1);
    	}
    	if(m_disconnectedCells[newPair.x][newPair.y] == false){
    		return (highestX - lowestX <= 1 && highestY-lowestY <= 1);
    	}
    	
    	
    	//check for bounds
    	
    	if(newPair.x < lowestX){
    		lowestX = newPair.x;
    	}
    	
    	if(newPair.x >highestX){
    		highestX = newPair.x;
    	}
    	if(newPair.y < lowestY){
    		lowestY = newPair.y;
    	}
    	if(newPair.y > highestY){
    		highestY = newPair.y;
    	}
    	
    	Pair top = new Pair(newPair);
    	top.y = top.y + 1;
    	
    	Pair topleft = new Pair(newPair);
    	topleft.y = topleft.y + 1;
    	topleft.x = topleft.x - 1;
    	
    	Pair topright = new Pair(newPair);
    	topright.y = topright.y + 1;
    	topright.y = topright.x + 1;
    	
    	Pair bot = new Pair(newPair);
    	bot.y = bot.y -1;
    	
    	Pair botleft = new Pair(newPair);
    	botleft.y = botleft.y -1;
    	botleft.x = botleft.x -1;
    	
    	Pair botright = new Pair(newPair);
    	botright.y = botright.y -1;
    	botright.x = botright.x + 1;
    	
    	Pair left = new Pair(newPair);
    	left.x = left.x - 1;
    	
    	Pair right = new Pair(newPair);
    	right.x = right.x  +1;
    	
    	return GapExceeds(top,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(topright,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(topleft,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(bot,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(botleft,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(botright,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(left,highestX,lowestX,highestY,lowestY,visited) && 
    			GapExceeds(right,highestX,lowestX,highestY,lowestY,visited);
    }
    
    public void init() {
    	Pair [] actionsForLayer;
    	
        random = new Random(seedZero);
    	stateNames = new String[xWidth][yWidth];
    	for(int x = 0; x < xWidth; x++){
    		for(int y = 0; y < yWidth; y++){
    			stateNames[x][y] = x + "," + y;
    			for(int i = 0; i < xWidth; i++){
    				for(int j = 0; j < yWidth; j++){
    					Q[x][y][i][j] = 0;
    					R[x][y][i][j] = 0;
    				}
    			}
    		}
    	}
    	
    	for(int x = 0; x < xWidth; x++){
    		for(int y = 0; y < yWidth; y++){
    			m_disconnectedCells[x][y] = false;
    		}
    	}
    	
    	
    	//Pick the gaps. Gaps can be no more than two blocks by two blocks, no two gaps can be touching
    	for(int x = 0; x < xWidth; x++){
    		for(int y = 0; y < yWidth; y++){
    			//Check to see if placing a gap cell here would be an issue
    			Pair newPair = new Pair();
    			ArrayList<Pair> empty = new ArrayList<Pair>();
    			newPair.x = x;
    			newPair.y = y;
    			if(random.nextInt(100) > 50 && newPair.x != m_goalStateX && newPair.y != m_goalStateY){
	    			m_disconnectedCells[newPair.x][newPair.y] = true;
	    			if(!GapExceeds(newPair,x,y,x,y,empty)){
	    				m_disconnectedCells[newPair.x][newPair.y] = false;
	    			}
    			}
    			
    		}
    	}
    	
    	for(int x = 0; x < xWidth; x++){
    		for (int y = 0; y < yWidth; y++){
    			System.out.print(m_disconnectedCells[x][y] + "");
    		}
    		System.out.println("");
    	}
    	
    	m_goalStateX = random.nextInt(xWidth);
    	m_goalStateY = random.nextInt(yWidth);
    	actions = new Pair[xWidth][yWidth][];
    	for(int x = 0; x < xWidth; x++){
    		for(int y = 0; y < yWidth; y++){

    			int numConnections = 0;
    			if(!(y+1 <0 || y+1 >= yWidth) && m_disconnectedCells[x][y+1] == false){
    				numConnections++;
    			}
    			if(!(x+1 <0 || x+1 >= xWidth) && m_disconnectedCells[x+1][y] == false){
    				numConnections++;
    			}
    			
    			if(!(y-1 <0 || y-1 >= yWidth) && m_disconnectedCells[x][y-1] == false){
    				numConnections++;
    			}
    			if(!(x-1 <0 || x-1 >= xWidth) && m_disconnectedCells[x-1][y] == false){
    				numConnections++;
    			}
    			
    			
    			actionsForLayer = new Pair[numConnections];
    			
    			int pos = 0;
    			
    			if(!(y+1 <0 || y+1 >= yWidth) && m_disconnectedCells[x][y+1] == false){
    				Pair p = new Pair();
					p.x = x;
					p.y = y+1;
					actionsForLayer[pos] = p;
					if(p.x == m_goalStateX && p.y == m_goalStateY){
						R[x][y][p.x][p.y] = 100;
					}
					
					pos++;
    			}
    			if(!(x+1 <0 || x+1 >= xWidth) && m_disconnectedCells[x+1][y] == false){
    				Pair p = new Pair();
					p.x = x+1;
					p.y = y;
					actionsForLayer[pos] = p;
					if(p.x == m_goalStateX && p.y == m_goalStateY){
						R[x][y][p.x][p.y] = 100;
					}
					
					pos++;
    			}
    			
    			if(!(y-1 <0 || y-1 >= yWidth) && m_disconnectedCells[x][y-1] == false){
    				Pair p = new Pair();
					p.x = x;
					p.y = y-1;
					actionsForLayer[pos] = p;
					if(p.x == m_goalStateX && p.y == m_goalStateY){
						R[x][y][p.x][p.y] = 100;
					}
					
					pos++;
    			}
    			if(!(x-1 <0 || x-1 >= xWidth) && m_disconnectedCells[x-1][y] == false){
    				Pair p = new Pair();
					p.x = x-1;
					p.y = y;
					actionsForLayer[pos] = p;
					if(p.x == m_goalStateX && p.y == m_goalStateY){
						R[x][y][p.x][p.y] = 100;
					}
					
					pos++;
    			}
    			
    			
    			actions[x][y] = actionsForLayer;
    		}
    	}
    	
    	//Randomly generate the graph
    	
    }
 
    public static void main(String[] args) throws IOException {
    	// If file already exists, will overwrite file
        // Be sure to change file after every test
        String path = "E:\\Development\\SchoolWork Spring 2016\\Learning and Advanced Game AI\\QLearning\\Output\\test.txt";
        BufferedWriter bufferedwriter = new BufferedWriter(new FileWriter(new File(path)));
        bufferedwriter.write("Alpha:   " + showalpha); bufferedwriter.newLine();
        bufferedwriter.write("Gamma:   " + showgamma); bufferedwriter.newLine(); 
        bufferedwriter.write("Epsilon: " + showepsilon); bufferedwriter.newLine(); bufferedwriter.newLine();

        long BEGIN = System.currentTimeMillis();

        Qlearning obj = new Qlearning();
        
        obj.run();
        obj.printResult(bufferedwriter);
        obj.showPolicy(bufferedwriter);
 
        long END = System.currentTimeMillis();
        System.out.println("Time: " + (END - BEGIN) / 1000.0 + " sec.");
        bufferedwriter.newLine();
        bufferedwriter.write("Time: " + (END-BEGIN) / 1000.0 + "sec.");
        bufferedwriter.newLine();
        bufferedwriter.close(); 
    }
 
    void run() {
        /*
         1. Set parameter , and environment reward matrix R 
         2. Initialize matrix Q as zero matrix 
         3. For each episode: Select random initial state 
            Do while not reach goal state o 
                Select one among all possible actions for the current state o 
                Using this possible action, consider to go to the next state o 
                Get maximum Q value of this next state based on all possible actions o 
                Compute o Set the next state as the current state
         */
 
        // For each episode
        
        
        for (int i = 0; i < 1000; i++) { // train episodes
        	
        	//TODO: implement epsilon value
        	
            // Select random initial state
        	Pair state = new Pair();
        	
            state.x = random.nextInt(xWidth);
            state.y = random.nextInt(yWidth);
            while (!(state.x == m_goalStateX && state.y == m_goalStateY)) // goal state
            {
                // Select one among all possible actions for the current state
                Pair[] actionsFromState = actions[state.x][state.y];
                if(actionsFromState.length > 0)
                {
                	 int rangemax = 50;
                     int rangemin = 0;
                     Pair action;
                     if (random.nextInt(rangemax)+rangemin < epsilon)
                     {
                     	int x = random.nextInt(actionsFromState.length);
                     	action = actionsFromState[x];
                     }
                     else
                     {
		            	
		                // Selection strategy is random in this example
		                int index = random.nextInt(actionsFromState.length);
		                action = actionsFromState[index];
		 
                     }
		                 
	                // Action outcome is set to deterministic in this example
	                // Transition probability is 1
	                Pair nextState = action; // data structure
	                // Using this possible action, consider to go to the next state
	                double q = Q(state, nextState);
	            	//System.out.println(state.x + " " + state.y + " " + action.x + " " + action.y);
	                double maxQ = maxQ(nextState);
	                int r = R(state, nextState);
	                
	                
	                
	                double value = q + alpha * (r + gamma * maxQ - q);
	               
	                setQ(state, action, value);
	 
	                // Set the next state as the current state
	                state = nextState;
                }
                else{
                	state.x = random.nextInt(xWidth);
                    state.y = random.nextInt(yWidth);
                }
            }
        }
    }
 
    double maxQ(Pair nextState2) {
        Pair[] actionsFromState = actions[nextState2.x][nextState2.y];
        
        double maxValue = Double.MIN_VALUE;
       // System.out.println(actionsFromState.length);
        for (int i = 0; i < actionsFromState.length; i++) {
            Pair nextState = actionsFromState[i];
            double value = 0;
           // System.out.println(nextState2.x + " " + nextState2.y + " " + nextState.x + " " + nextState.y);
            value = Q[nextState2.x][nextState2.y][nextState.x][nextState.y];
 
            if (value > maxValue)
                maxValue = value;
        }
        return maxValue;
    }
 
    // get policy from state
    Pair policy(Pair state, boolean epsilonEnabled) {
        Pair[] actionsFromState = actions[state.x][state.y];
        double maxValue = Double.MIN_VALUE;
        Pair policyGotoState = state; // default goto self if not found
        
        for (int i = 0; i < actionsFromState.length; i++) {
        	Pair nextState = actionsFromState[i];
            double value = Q[state.x][state.y][nextState.x][nextState.y];
 
            if (value > maxValue) {
                maxValue = value;
                policyGotoState = nextState;
            }
        }
        
        return policyGotoState;
    }
 
    double Q(Pair state, Pair action) {
    	return Q[state.x][state.y][action.x][action.y];
    	
    }
 
    void setQ(Pair s, Pair a, double value) {    	
        Q[s.x][s.y][a.x][a.y] = value;
    }
 
    int R(Pair s, Pair a) {
        return R[s.x][s.y][a.x][a.y];
    }
 
    void printResult(BufferedWriter bw) throws IOException {
        System.out.println("Print result");
        bw.write("Results:");
        bw.newLine(); bw.newLine();
        ArrayList<ArrayList<String>> results = new ArrayList<ArrayList<String>>();
        
        for (int i = 0; i < stateNames.length; i++) {
            for (int j = 0; j < stateNames[i].length; j++) {
                System.out.print("out from " + stateNames[i][j] + ":  ");
                
                ArrayList<String> column = new ArrayList<String>();
                column.add(stateNames[i][j]);
                
                for(int k = 0; k < Q[i][j].length; k++){
                	for(int l = 0; l < Q[i][j][k].length; l++){
                		System.out.print(df.format(Q[i][j][k][l]) + " ");
                		String reward = String.valueOf(Q[i][j][k][l]);
                		column.add(reward);
                	}
                }
                results.add(column);
                	
            System.out.println();
            }
        }

        // *** Text File Visualization: Matrix
        bw.write("Matrix:"); bw.newLine();
        bw.write("      ");
        for (int x = 0; x < results.size(); x++)
        {
        	bw.write("  " + results.get(x).get(0) + "  ");
        }
        bw.newLine();
        bw.write("      ");
        for (int y = 0; y < results.size();y++)
        {
        	bw.write("-------");
        }
        bw.newLine();

        for(int j = 0; j < results.size(); j++)
        {
        	int count = 0;
        	while (count<results.size()+1)
        	{
        		String temp = results.get(j).get(count);
        		int size = temp.length();
        		if (count == 0)
        		{
        			if (size == 3)
        			{
        				bw.write(" " + temp + " |");
        			}
        			else if (size == 2)
        			{
        				bw.write("  " + temp + " |");
        			}
        			else
        			{
        				bw.write("  " + temp + "  |");
        			}
        		}
        		else
        		{
            		double val = Double.parseDouble(temp);
            		String a = df.format(val);
            		int size1 = a.length();
        			if (size1 == 1)
        			{
        				bw.write("   " + df.format(Double.parseDouble(temp)) + "   ");
        			}
        			else if (size1 == 2)
        			{
        				bw.write("  " + df.format(Double.parseDouble(temp)) + "   ");
        			}
        			else if (size1 == 3)
        			{
        				bw.write("  " + df.format(Double.parseDouble(temp)) + "  "); 
        			}
        			else if (size1 == 4)
        			{
        				bw.write(" " + df.format(Double.parseDouble(temp)) + "  "); 
        			}
        			else if (size1 == 5)
        			{
        				bw.write(" " + df.format(Double.parseDouble(temp)) + " ");
        			}
        		}
        		count++;
        	}
        	bw.newLine();
        }
        // END MATRIX HERE
    }
 
    // policy is maxQ(states)
    void showPolicy(BufferedWriter bw) throws IOException {
    	System.out.println("Starting movement test suite.");

    	
    	//show which each cell will output to
    	for(int x = 0; x < xWidth; x++){
    		for(int y = 0; y < yWidth; y++){
    			System.out.println(stateNames[xWidth][yWidth] + " goes to ");
    		}
    	}
    	//show ten traversals of the graph
    	
    	for(int i = 0; i < 10; i++){
    		System.out.println("Test no. " + i);
    		//Pick a random starting point
    		
    		Pair sp = new Pair();
    		sp.x = random.nextInt(xWidth);
    		sp.y = random.nextInt(yWidth);
    		
    		
    	}
    }
}
